{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — LightAutoML Baseline\n",
    "\n",
    "Реализован бейслайн на LAMA с GPU. План:\n",
    "\n",
    "1. Подключение общих утилит.\n",
    "2. Подготовка данных на EDA.\n",
    "3. Формирование стратегии split без утечки.\n",
    "4. Запуск LightAutoML.\n",
    "5. Сравнение метрик, выбор лучшей модели, сохранение артефактов.\n",
    "6. Анализ результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea543d8c",
   "metadata": {},
   "source": [
    "## 0. Подготовка окружения и импортов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb477f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependency package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependency package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ak\\anaconda3\\Lib\\site-packages\\lightautoml\\ml_algo\\dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "c:\\Users\\ak\\anaconda3\\Lib\\site-packages\\lightautoml\\text\\embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "c:\\Users\\ak\\anaconda3\\Lib\\site-packages\\lightautoml\\text\\dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\cursor projects\\automl2025\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "try:\n",
    "    from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "    from lightautoml.tasks import Task\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\n",
    "        \"LightAutoML не установлен. Выполните `pip install lightautoml` в используемом окружении и перезапустите ядро.\"\n",
    "    ) from exc\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\", \"\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_COL = \"hospital_death\"\n",
    "ID_COL = \"encounter_id\"\n",
    "RANDOM_STATE = 42\n",
    "FOLDS = 5\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90d15a",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных и первичная обработка\n",
    "\n",
    "Используем CSV-файлы.\n",
    "- удаляем признаки с >40% пропусков;\n",
    "- добавляем биннинги возраста/ИМТ, взаимодействие `apache` и отношение LOS;\n",
    "- считаем средние по смертности для `hospital_id`/`icu_type`/`apache_3j_bodysystem` (target-like статистики из train).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d6f01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>hospital_death</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>...</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>bmi_missing</th>\n",
       "      <th>bmi_bucket</th>\n",
       "      <th>age_bucket</th>\n",
       "      <th>apache_prob_interaction</th>\n",
       "      <th>hospital_id_death_rate</th>\n",
       "      <th>icu_type_death_rate</th>\n",
       "      <th>apache_3j_bodysystem_death_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>0</td>\n",
       "      <td>(14.844000000000001, 22.769]</td>\n",
       "      <td>[65, 80)</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.070621</td>\n",
       "      <td>0.060205</td>\n",
       "      <td>0.157922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>0</td>\n",
       "      <td>(26.059, 29.445]</td>\n",
       "      <td>[65, 80)</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.087495</td>\n",
       "      <td>0.112068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119783</td>\n",
       "      <td>50777</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>0</td>\n",
       "      <td>(29.445, 34.49]</td>\n",
       "      <td>[0, 30)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.070621</td>\n",
       "      <td>0.087495</td>\n",
       "      <td>0.015163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79267</td>\n",
       "      <td>46918</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>0</td>\n",
       "      <td>(14.844000000000001, 22.769]</td>\n",
       "      <td>[80, 120)</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.070621</td>\n",
       "      <td>0.060205</td>\n",
       "      <td>0.079669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92056</td>\n",
       "      <td>34377</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>[0, 30)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027864</td>\n",
       "      <td>0.087495</td>\n",
       "      <td>0.067413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_id  hospital_id  hospital_death   age    bmi  \\\n",
       "0         66154       25312          118               0  68.0  22.73   \n",
       "1        114252       59342           81               0  77.0  27.42   \n",
       "2        119783       50777          118               0  25.0  31.95   \n",
       "3         79267       46918          118               0  81.0  22.64   \n",
       "4         92056       34377           33               0  19.0    NaN   \n",
       "\n",
       "   elective_surgery  ethnicity gender  height  ...  \\\n",
       "0                 0  Caucasian      M   180.3  ...   \n",
       "1                 0  Caucasian      F   160.0  ...   \n",
       "2                 0  Caucasian      F   172.7  ...   \n",
       "3                 1  Caucasian      F   165.1  ...   \n",
       "4                 0  Caucasian      M   188.0  ...   \n",
       "\n",
       "  solid_tumor_with_metastasis apache_3j_bodysystem  apache_2_bodysystem  \\\n",
       "0                         0.0               Sepsis       Cardiovascular   \n",
       "1                         0.0          Respiratory          Respiratory   \n",
       "2                         0.0            Metabolic            Metabolic   \n",
       "3                         0.0       Cardiovascular       Cardiovascular   \n",
       "4                         0.0               Trauma               Trauma   \n",
       "\n",
       "  bmi_missing                    bmi_bucket  age_bucket  \\\n",
       "0           0  (14.844000000000001, 22.769]    [65, 80)   \n",
       "1           0              (26.059, 29.445]    [65, 80)   \n",
       "2           0               (29.445, 34.49]     [0, 30)   \n",
       "3           0  (14.844000000000001, 22.769]   [80, 120)   \n",
       "4           1                           nan     [0, 30)   \n",
       "\n",
       "   apache_prob_interaction  hospital_id_death_rate  icu_type_death_rate  \\\n",
       "0                   0.0050                0.070621             0.060205   \n",
       "1                   0.1363                0.043103             0.087495   \n",
       "2                   0.0000                0.070621             0.087495   \n",
       "3                   0.0012                0.070621             0.060205   \n",
       "4                      NaN                0.027864             0.087495   \n",
       "\n",
       "   apache_3j_bodysystem_death_rate  \n",
       "0                         0.157922  \n",
       "1                         0.112068  \n",
       "2                         0.015163  \n",
       "3                         0.079669  \n",
       "4                         0.067413  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIGH_MISSING_THRESHOLD = 0.4\n",
    "GROUP_STAT_COLS = [\"hospital_id\", \"icu_type\", \"apache_3j_bodysystem\"]\n",
    "\n",
    "\n",
    "def add_feature_engineering(df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "    result = df.copy()\n",
    "\n",
    "    if \"bmi\" in result.columns:\n",
    "        result[\"bmi_missing\"] = result[\"bmi\"].isna().astype(int)\n",
    "        result[\"bmi_bucket\"] = pd.qcut(result[\"bmi\"], q=5, duplicates=\"drop\")\n",
    "\n",
    "    if \"age\" in result.columns:\n",
    "        result[\"age_bucket\"] = pd.cut(result[\"age\"], bins=[0, 30, 50, 65, 80, 120], right=False)\n",
    "\n",
    "    if {\"apache_4a_hospital_death_prob\", \"apache_4a_icu_death_prob\"}.issubset(result.columns):\n",
    "        result[\"apache_prob_interaction\"] = (\n",
    "            result[\"apache_4a_hospital_death_prob\"] * result[\"apache_4a_icu_death_prob\"]\n",
    "        )\n",
    "\n",
    "    if {\"pre_icu_los_days\", \"icu_los_days\"}.issubset(result.columns):\n",
    "        result[\"los_ratio\"] = (\n",
    "            result[\"pre_icu_los_days\"].fillna(0) / (result[\"icu_los_days\"].fillna(1) + 1e-3)\n",
    "        )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_group_statistics(\n",
    "    train_df: pd.DataFrame, test_df: pd.DataFrame, group_cols: List[str], target_col: str\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    global_mean = train_df[target_col].mean()\n",
    "    for col in group_cols:\n",
    "        if col not in train_df.columns:\n",
    "            continue\n",
    "        mapping = train_df.groupby(col)[target_col].mean()\n",
    "        train_df[f\"{col}_death_rate\"] = train_df[col].map(mapping)\n",
    "        test_df[f\"{col}_death_rate\"] = test_df[col].map(mapping).fillna(global_mean)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def load_datasets(data_dir: Path) -> Dict[str, pd.DataFrame]:\n",
    "    train_path = data_dir / \"training_v2.csv\"\n",
    "    test_path = data_dir / \"unlabeled.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            \"Не найдены CSV-файлы\"\n",
    "        )\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_df = train_df.drop_duplicates(subset=ID_COL)\n",
    "    test_df = test_df.drop_duplicates(subset=ID_COL)\n",
    "\n",
    "    missing_share = train_df.isna().mean()\n",
    "    keep_cols = missing_share[missing_share <= HIGH_MISSING_THRESHOLD].index.tolist()\n",
    "    keep_cols += [TARGET_COL, ID_COL, \"patient_id\"]\n",
    "    keep_cols = list(dict.fromkeys(keep_cols))\n",
    "\n",
    "    train_df = train_df[keep_cols].copy()\n",
    "    test_df = test_df[[col for col in keep_cols if col != TARGET_COL]].copy()\n",
    "\n",
    "    train_df = add_feature_engineering(train_df, is_train=True)\n",
    "    test_df = add_feature_engineering(test_df, is_train=False)\n",
    "    train_df, test_df = add_group_statistics(train_df, test_df, GROUP_STAT_COLS, TARGET_COL)\n",
    "\n",
    "    cat_cols = train_df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    for col in cat_cols:\n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        if col in test_df.columns:\n",
    "            test_df[col] = test_df[col].astype(str)\n",
    "\n",
    "    return {\"train\": train_df, \"test\": test_df}\n",
    "\n",
    "\n",
    "data = load_datasets(DATA_DIR)\n",
    "train_df, test_df = data[\"train\"], data[\"test\"]\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3b96bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (91713, 119), Test shape: (39308, 118)\n",
      "hospital_death\n",
      "0    0.913698\n",
      "1    0.086302\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "print(train_df[TARGET_COL].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e8c37",
   "metadata": {},
   "source": [
    "## 2. Стратегия валидации\n",
    "\n",
    "Используем `StratifiedKFold` (5 фолдов, фиксированный seed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ccfb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5 folds for CV\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in train_df.columns if col not in {TARGET_COL}]\n",
    "train_data = train_df[feature_cols + [TARGET_COL]].copy()\n",
    "\n",
    "task = Task(\"binary\", loss=\"logloss\")\n",
    "folds = list(\n",
    "    StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE).split(\n",
    "        train_data[feature_cols], train_data[TARGET_COL]\n",
    "    )\n",
    ")\n",
    "print(f\"Prepared {len(folds)} folds for CV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12737c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lama_experiment(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    preset_params: dict,\n",
    "    exp_name: str,\n",
    ") -> dict:\n",
    "    \"\"\"Обучает TabularAutoML и возвращает метрики/предсказания.\"\"\"\n",
    "\n",
    "    automl = TabularAutoML(task=task, **preset_params)\n",
    "    oof_pred = automl.fit_predict(\n",
    "        train_df,\n",
    "        roles={\"target\": TARGET_COL, \"drop\": [ID_COL]},\n",
    "        cv_iter=folds,\n",
    "        verbose=1,\n",
    "    )\n",
    "    oof_score = roc_auc_score(train_df[TARGET_COL], oof_pred.data[:, 0])\n",
    "\n",
    "    test_pred = automl.predict(test_df)\n",
    "    submission = pd.DataFrame({\n",
    "        ID_COL: test_df[ID_COL],\n",
    "        TARGET_COL: test_pred.data[:, 0],\n",
    "    })\n",
    "    submission_path = MODELS_DIR / f\"submission_{exp_name}.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "\n",
    "    return {\n",
    "        \"score\": oof_score,\n",
    "        \"submission_path\": submission_path,\n",
    "        \"predictions\": submission,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac687cf",
   "metadata": {},
   "source": [
    "## 3. LightAutoML конфигурация A\n",
    "\n",
    "Первая конфигурация — быстрый GPU preset с небольшим временем обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be3e2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:40] Stdout logging level is INFO.\n",
      "[15:19:40] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[15:19:40] Task: binary\n",
      "\n",
      "[15:19:40] Start automl preset with listed constraints:\n",
      "[15:19:40] - time: 3600.00 seconds\n",
      "[15:19:40] - CPU: 4 cores\n",
      "[15:19:40] - memory: 16 GB\n",
      "\n",
      "[15:19:40] \u001b[1mTrain data shape: (91713, 119)\u001b[0m\n",
      "\n",
      "[15:19:51] Layer \u001b[1m1\u001b[0m train process start. Time left 3588.61 secs\n",
      "[15:20:04] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:20:08] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:21:08] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9010776395970835\u001b[0m\n",
      "[15:21:08] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:21:08] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m ...\n",
      "[15:22:35] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m finished. score = \u001b[1m0.9003271064398358\u001b[0m\n",
      "[15:22:35] \u001b[1mLvl_0_Pipe_0_Mod_1_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:22:35] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m ...\n",
      "[15:22:55] Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m finished. score = \u001b[1m0.8895706204239274\u001b[0m\n",
      "[15:22:55] \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m fitting and predicting completed\n",
      "[15:22:55] Time left 3405.55 secs\n",
      "\n",
      "[15:22:55] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:22:55] Blending: optimization starts with equal weights. Score = \u001b[1m0.9033660\u001b[0m\n",
      "[15:22:55] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9037769\u001b[0m, weights = \u001b[1m[0.42769295 0.39437342 0.17793356]\u001b[0m\n",
      "[15:22:55] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9037897\u001b[0m, weights = \u001b[1m[0.47583133 0.3563789  0.16778976]\u001b[0m\n",
      "[15:22:56] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9037909\u001b[0m, weights = \u001b[1m[0.46128368 0.36692908 0.17178723]\u001b[0m\n",
      "[15:22:56] Blending: no improvements for score. Terminated.\n",
      "\n",
      "[15:22:56] Blending: best score = \u001b[1m0.9037909\u001b[0m, best weights = \u001b[1m[0.46128368 0.36692908 0.17178723]\u001b[0m\n",
      "[15:22:56] \u001b[1mAutoml preset training completed in 196.14 seconds\u001b[0m\n",
      "\n",
      "[15:22:56] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.46128 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) +\n",
      "\t 0.36693 * (5 averaged models Lvl_0_Pipe_0_Mod_1_CatBoost) +\n",
      "\t 0.17179 * (5 averaged models Lvl_0_Pipe_0_Mod_2_XGBoost) \n",
      "\n",
      "Config A ROC-AUC: 0.9038\n"
     ]
    }
   ],
   "source": [
    "preset_a_params = {\n",
    "    \"gpu_ids\": \"0\",\n",
    "    \"timeout\": 3600,  # 1 час ограничение\n",
    "    \"reader_params\": {\n",
    "        \"n_jobs\": 4,\n",
    "    },\n",
    "    \"general_params\": {\n",
    "        \"use_algos\": [[\"lgb\", \"cb\", \"xgb\"]],\n",
    "    },\n",
    "}\n",
    "\n",
    "results_a = run_lama_experiment(train_data, test_df[feature_cols], preset_a_params, \"gpu_tiny\")\n",
    "print(f\"Config A ROC-AUC: {results_a['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a980c2",
   "metadata": {},
   "source": [
    "## 4. LightAutoML конфигурация B\n",
    "\n",
    "Второй запуск. Более тяжёлый с расширенным стеком, увеличиваем `timeout` и включаем feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa99d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:23:00] Stdout logging level is INFO.\n",
      "[15:23:00] Task: binary\n",
      "\n",
      "[15:23:00] Start automl preset with listed constraints:\n",
      "[15:23:00] - time: 7200.00 seconds\n",
      "[15:23:00] - CPU: 4 cores\n",
      "[15:23:00] - memory: 16 GB\n",
      "\n",
      "[15:23:00] \u001b[1mTrain data shape: (91713, 119)\u001b[0m\n",
      "\n",
      "[15:23:08] Layer \u001b[1m1\u001b[0m train process start. Time left 7192.40 secs\n",
      "[15:23:12] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[15:23:32] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8935206315485046\u001b[0m\n",
      "[15:23:32] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[15:23:32] Time left 7167.88 secs\n",
      "\n",
      "[15:23:47] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:23:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[15:25:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9010776395970835\u001b[0m\n",
      "[15:25:04] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[15:25:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_CatBoost\u001b[0m ...\n",
      "[15:26:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_CatBoost\u001b[0m finished. score = \u001b[1m0.9003271064398358\u001b[0m\n",
      "[15:26:45] \u001b[1mLvl_0_Pipe_1_Mod_1_CatBoost\u001b[0m fitting and predicting completed\n",
      "[15:26:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGBoost\u001b[0m ...\n",
      "[15:27:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGBoost\u001b[0m finished. score = \u001b[1m0.8895706204239274\u001b[0m\n",
      "[15:27:03] \u001b[1mLvl_0_Pipe_1_Mod_2_XGBoost\u001b[0m fitting and predicting completed\n",
      "[15:27:03] Time left 6956.77 secs\n",
      "\n",
      "[15:27:03] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[15:27:03] Blending: optimization starts with equal weights. Score = \u001b[1m0.9040549\u001b[0m\n",
      "[15:27:04] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9043540\u001b[0m, weights = \u001b[1m[0.14471224 0.41484213 0.28395844 0.15648717]\u001b[0m\n",
      "[15:27:04] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9043667\u001b[0m, weights = \u001b[1m[0.16469243 0.42839903 0.24588269 0.16102587]\u001b[0m\n",
      "[15:27:05] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9043680\u001b[0m, weights = \u001b[1m[0.1716065  0.41793323 0.24968667 0.16077356]\u001b[0m\n",
      "[15:27:06] Blending: no improvements for score. Terminated.\n",
      "\n",
      "[15:27:06] Blending: best score = \u001b[1m0.9043680\u001b[0m, best weights = \u001b[1m[0.1716065  0.41793323 0.24968667 0.16077356]\u001b[0m\n",
      "[15:27:06] \u001b[1mAutoml preset training completed in 245.39 seconds\u001b[0m\n",
      "\n",
      "[15:27:06] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.17161 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.41793 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.24969 * (5 averaged models Lvl_0_Pipe_1_Mod_1_CatBoost) +\n",
      "\t 0.16077 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGBoost) \n",
      "\n",
      "Config B ROC-AUC: 0.9044\n"
     ]
    }
   ],
   "source": [
    "preset_b_params = {\n",
    "    \"gpu_ids\": \"0\",\n",
    "    \"timeout\": 7200,  # до 2 часов\n",
    "    \"reader_params\": {\n",
    "        \"n_jobs\": 6,\n",
    "    },\n",
    "    \"general_params\": {\n",
    "        \"use_algos\": [[\"lgb\", \"cb\", \"xgb\", \"linear_l2\"]],\n",
    "        \"max_features_cnt\": 500,\n",
    "    },\n",
    "    \"tuning_params\": {\n",
    "        \"max_tuning_iter\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "results_b = run_lama_experiment(train_data, test_df[feature_cols], preset_b_params, \"gpu_extended\")\n",
    "print(f\"Config B ROC-AUC: {results_b['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4cc59",
   "metadata": {},
   "source": [
    "## 5. Сравнение результатов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d4020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPU extended</td>\n",
       "      <td>0.904368</td>\n",
       "      <td>submission_gpu_extended.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPU tiny</td>\n",
       "      <td>0.903791</td>\n",
       "      <td>submission_gpu_tiny.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         config   roc_auc                   submission\n",
       "1  GPU extended  0.904368  submission_gpu_extended.csv\n",
       "0      GPU tiny  0.903791      submission_gpu_tiny.csv"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame(\n",
    "    [\n",
    "        {\"config\": \"GPU tiny\", \"roc_auc\": results_a[\"score\"], \"submission\": results_a[\"submission_path\"].name},\n",
    "        {\"config\": \"GPU extended\", \"roc_auc\": results_b[\"score\"], \"submission\": results_b[\"submission_path\"].name},\n",
    "    ]\n",
    ")\n",
    "comparison.sort_values(\"roc_auc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb9ada",
   "metadata": {},
   "source": [
    "**Вывод:** Конфигурация с расширенными настройками покала лучший результат (roc_auc 0.904368). Берем её за условный бейслайн\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3cd907",
   "metadata": {},
   "source": [
    "## 6. Вывод\n",
    "\n",
    "- Файл submission_gpu_extended.csv сабмитим на Kaggle. Кастомное решение будем сравнивать с ним."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
